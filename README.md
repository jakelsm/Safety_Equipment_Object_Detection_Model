# 안전장비 객체인식 모델

이 프로젝트는 **안전장비 객체인식 모델**을 개발하는 것을 목표로 합니다. 딥러닝 기반 객체 인식 기술을 활용하여 다양한 안전장비를 감지하며, 작업장 안전 및 규정 준수 모니터링을 지원합니다. 프로젝트는 Google Colab 환경에서 구현되었으며, YOLOv7 및 Faster R-CNN과 같은 최신 객체 인식 알고리즘을 사용하여 실현되었습니다.

---

## 📄 주요 자료
- **최종 발표 자료 (PPT)**: `캡스톤3조.pptx`  
  프로젝트의 배경, 목표, 사용 기술 및 구현 내용을 포함한 발표 자료입니다.
- **최종 결과 보고서**: `캡스톤3조+결과보고서.hwp`  
  프로젝트의 전체 과정과 결과를 상세히 기록한 문서입니다.
- **코드 파일**: `산업경영빅데이터공학과_20192372_이승민_캡스톤디자인.ipynb`  
  안전장비 객체인식 모델 구현에 사용된 주요 코드가 포함된 Jupyter Notebook 파일입니다.

---

## 주요 내용

### 1. 프로젝트 개요
- **목표**: 작업장에서 사용되는 다양한 안전장비를 인식하여 안전 모니터링과 규정 준수를 지원.
- **사용 기술**:
  - Faster R-CNN: 정확도 높은 객체 탐지를 위한 모델.
  - YOLOv7: 경량화와 실시간 탐지를 위한 모델.
- **모델 아키텍처**:
  - YOLOv7S: 빠르고 경량화된 모델.
  - YOLOv7M: 속도와 정확도 사이의 균형을 유지.
  - YOLOv7L: 가장 높은 정확도를 기록.

---

### 2. 데이터 및 전처리
- **데이터 출처**:
  - 작업장에서 사용되는 안전장비 이미지 데이터셋.
- **전처리 과정**:
  - 이미지 라벨링: CVAT 도구를 활용하여 안전장비 객체에 대한 라벨링 수행.
  - 데이터 증강: 다양한 각도, 밝기, 스케일 변화를 통해 데이터 다양성 확보.

---

### 3. 시스템 구현
- **구현 환경**:
  - Google Colab에서 Python 및 Jupyter Notebook을 사용하여 구현.
  - GPU를 활용한 빠른 학습 및 모델 평가.
- **사용 기술**:
  - YOLOv7 및 Faster R-CNN 모델을 각각 학습 및 성능 비교.
  - Python 기반 데이터 처리 및 모델 구현.
- **주요 단계**:
  1. 데이터셋 준비 및 전처리.
  2. 모델 학습 및 평가.
  3. 탐지 결과 시각화 및 시스템 통합.

---

### 4. 주요 결과
- **모델 성능**:
  - YOLOv7S: 빠른 속도와 적절한 정확도 제공.
  - YOLOv7M: 속도와 정확도 사이의 균형을 유지.
  - YOLOv7L: 가장 높은 정확도를 기록.
  - Faster R-CNN: 세밀한 객체 탐지 성능 제공.
- **결과 시각화**:
  - 학습 및 테스트 데이터에서 안전장비 객체 탐지 결과를 시각화하여 시스템 성능 확인.

---

### 5. 사용법

#### 모델 학습
1. Google Colab에서 Jupyter Notebook 파일(`산업경영빅데이터공학과_20192372_이승민_캡스톤디자인.ipynb`)을 업로드하고 실행합니다.
2. YOLOv7 및 Faster R-CNN 모델을 학습시키고, 테스트 데이터를 사용해 성능을 평가합니다.
3. 학습 및 평가 과정에서 출력된 탐지 결과를 확인합니다.

#### 결과 확인
1. 탐지 결과는 이미지와 함께 Colab 출력 섹션에 시각화됩니다.
2. 학습된 모델 파일은 Colab 작업 디렉토리 또는 Google Drive에 저장됩니다.

---
